{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pip install azure-ai-textanalytics==5.2.0b1\r\n",
    "!pip install bs4\r\n",
    "!pip install requests"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# authenticate azure text analytics client\r\n",
    "from azure.ai.textanalytics import TextAnalyticsClient\r\n",
    "from azure.core.credentials import AzureKeyCredential\r\n",
    "\r\n",
    "key = \"677e7a68d2f94932a97572bfd9505ea3\"\r\n",
    "endpoint = \"https://covid-corruption-nlp2.cognitiveservices.azure.com/\"\r\n",
    "\r\n",
    "def authenticate_client():\r\n",
    "    ta_credential = AzureKeyCredential(key)\r\n",
    "    text_analytics_client = TextAnalyticsClient(\r\n",
    "            endpoint=endpoint, \r\n",
    "            credential=ta_credential)\r\n",
    "    return text_analytics_client\r\n",
    "\r\n",
    "client = authenticate_client()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# perform key phrase extraction\r\n",
    "def key_phrase_extraction(client, documents=\"\"):\r\n",
    "    try:\r\n",
    "        responses = client.extract_key_phrases(documents = documents)\r\n",
    "        \r\n",
    "        key_phrases = []\r\n",
    "        for response in responses:\r\n",
    "            if response.key_phrases:\r\n",
    "                key_phrases += response.key_phrases\r\n",
    "        \r\n",
    "        return key_phrases\r\n",
    "\r\n",
    "    except Exception as err:\r\n",
    "        print(\"Encountered exception. {}\".format(err))\r\n",
    "\r\n",
    "\r\n",
    "news_source = \"sky\"\r\n",
    "f_in = open('datasets/parsed-news/{}.txt'.format(news_source), 'r')\r\n",
    "documents = [line.rstrip() for line in f_in.readlines()]\r\n",
    "num_docs = len(documents)\r\n",
    "\r\n",
    "key_phrases = []\r\n",
    "for i in range(0, num_docs, 10):\r\n",
    "    print(i)\r\n",
    "    key_phrase = key_phrase_extraction(\r\n",
    "                    client, \r\n",
    "                    documents=documents[i: min(num_docs, i+10)]\r\n",
    "    )\r\n",
    "\r\n",
    "    if key_phrase:\r\n",
    "        key_phrases += key_phrase\r\n",
    "\r\n",
    "print(key_phrases)\r\n",
    "f_out = open('datasets/parsed-news/{}_phrases.txt'.format(news_source), 'w+')\r\n",
    "for phrase in key_phrases:\r\n",
    "    phrase = '-'.join(phrase.split())\r\n",
    "    f_out.write(phrase + '\\n')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit"
  },
  "interpreter": {
   "hash": "fe44fef87f92f48a3a32707d0df204585f471652bc0ce87358a3ce712bc24db0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}